{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Stock Prices Predictions with DeepAR**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Notebook will contain the modeling phases needed to predict stock prices using a deep learning model.\n",
    "The stocks analyzed will be the following:\n",
    "* IBM\n",
    "* AAPL (Apple Inc.)\n",
    "* AMZN (Amazon Inc.)\n",
    "* GOOGL (Alphabet Inc.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data must be prepared in order to be processed by DeepAR model:\n",
    "* Train/test set split\n",
    "* Save Data locally\n",
    "* Upload to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'stock_deepar'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The folder we will be used to store json data\n",
    "data_dir_json = os.path.join(data_dir, 'json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The folder we will be used to store csv data\n",
    "data_dir_csv = os.path.join(data_dir, 'csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The folder we will be used to store training data in json format\n",
    "data_dir_json_train = os.path.join(data_dir_json, 'train')\n",
    "data_dir_json_train_ibm = os.path.join(data_dir_json_train, 'IBM')\n",
    "data_dir_json_train_aapl = os.path.join(data_dir_json_train, 'AAPL')\n",
    "data_dir_json_train_amzn = os.path.join(data_dir_json_train, 'AMZN')\n",
    "data_dir_json_train_googl = os.path.join(data_dir_json_train, 'GOOGL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The folder we will be used to store test data in json format\n",
    "data_dir_json_test = os.path.join(data_dir_json, 'test')\n",
    "data_dir_json_test_ibm = os.path.join(data_dir_json_test, 'IBM')\n",
    "data_dir_json_test_aapl = os.path.join(data_dir_json_test, 'AAPL')\n",
    "data_dir_json_test_amzn = os.path.join(data_dir_json_test, 'AMZN')\n",
    "data_dir_json_test_googl = os.path.join(data_dir_json_test, 'GOOGL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The folder we will be used to store validation data in json format\n",
    "data_dir_json_valid = os.path.join(data_dir_json, 'validation')\n",
    "data_dir_json_valid_ibm = os.path.join(data_dir_json_valid, 'IBM')\n",
    "data_dir_json_valid_aapl = os.path.join(data_dir_json_valid, 'AAPL')\n",
    "data_dir_json_valid_amzn = os.path.join(data_dir_json_valid, 'AMZN')\n",
    "data_dir_json_valid_googl = os.path.join(data_dir_json_valid, 'GOOGL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The folder we will be used to store moving average benchmark model output data in json format\n",
    "data_dir_json_benchmark = os.path.join(data_dir_json, 'benchmark')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing train/test dataframe lists to iterate on them\n",
    "dfs_train = [df_ibm_train, df_aapl_train, df_amzn_train, df_googl_train]\n",
    "dfs_test = [df_ibm_test, df_aapl_test, df_amzn_test, df_googl_test]\n",
    "dfs_valid = [df_ibm_valid, df_aapl_valid, df_amzn_valid, df_googl_valid]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Data Locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(data_dir_csv): # Make sure that the folder exists\n",
    "    os.makedirs(data_dir_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IBM\n",
    "df_ibm_train.to_csv(os.path.join(data_dir_csv, 'ibm_train.csv'), header=True, index=True)\n",
    "df_ibm_test.to_csv(os.path.join(data_dir_csv, 'ibm_test.csv'), header=True, index=True)\n",
    "df_ibm_valid.to_csv(os.path.join(data_dir_csv, 'ibm_valid.csv'), header=True, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apple Inc.\n",
    "df_aapl_train.to_csv(os.path.join(data_dir_csv, 'aapl_train.csv'), header=True, index=True)\n",
    "df_aapl_test.to_csv(os.path.join(data_dir_csv, 'aapl_test.csv'), header=True, index=True)\n",
    "df_aapl_valid.to_csv(os.path.join(data_dir_csv, 'aapl_valid.csv'), header=True, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Amazon.com\n",
    "df_amzn_train.to_csv(os.path.join(data_dir_csv, 'amzn_train.csv'), header=True, index=True)\n",
    "df_amzn_test.to_csv(os.path.join(data_dir_csv, 'amzn_test.csv'), header=True, index=True)\n",
    "df_amzn_valid.to_csv(os.path.join(data_dir_csv, 'amzn_valid.csv'), header=True, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alphabet Inc.\n",
    "df_googl_train.to_csv(os.path.join(data_dir_csv, 'googl_train.csv'), header=True, index=True)\n",
    "df_googl_test.to_csv(os.path.join(data_dir_csv, 'googl_test.csv'), header=True, index=True)\n",
    "df_googl_valid.to_csv(os.path.join(data_dir_csv, 'googl_valid.csv'), header=True, index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JSON serialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to feed DeepAR model, JSON files must be prepared from data.\n",
    "I'll dispose two kind of JSON inputs:\n",
    "* one with \"dynamic features\", to use a DeepAR API terminology: all dataset features except for target column and related one ('Adj Close', 'Close');\n",
    "* one without \"dynamic features: only 'Adj Close' column will be fed to DeepAR model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DataFrame to JSON conversion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I'm going to convert data to JSON file format, in order to feed the DeepAR model correctly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As already announced, I will create two kind of time series, one with a list of dynamic features `dyn_feat`and the other one with only the target column (`Adj Close`) time series. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating local storage path:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(data_dir_json): # Make sure that the folder exists\n",
    "    os.makedirs(data_dir_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Serializing data to json files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "from source_deepar.deepar_utils import ts2dar_json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset with the `Adj Close` time series alone:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(data_dir_json_train): # Make sure that the folder exists\n",
    "    os.makedirs(data_dir_json_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df, m in zip(dfs_train, mnemonics):\n",
    "    ts2dar_json(df, data_dir_json_train, m+'.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(data_dir_json_test): # Make sure that the folder exists\n",
    "    os.makedirs(data_dir_json_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df, m in zip(dfs_test, mnemonics):\n",
    "    ts2dar_json(df, data_dir_json_test, m+'.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(data_dir_json_valid): # Make sure that the folder exists\n",
    "    os.makedirs(data_dir_json_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df, m in zip(dfs_valid, mnemonics):\n",
    "    ts2dar_json(df, data_dir_json_valid, m+'.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmark data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(data_dir_json_benchmark): # Make sure that the folder exists\n",
    "    os.makedirs(data_dir_json_benchmark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s, m in zip(ser_valid_ma, mnemonics):\n",
    "    ts2dar_json(df, data_dir_json_benchmark, m+'.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AWS declarations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining training data Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define IAM role and session\n",
    "role = sagemaker.get_execution_role()\n",
    "sagemaker_session = sagemaker.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "interval ='D'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define S3 variables for model train artifacts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define training data location\n",
    "s3_data_key = 'train_artifacts'\n",
    "s3_bucket = sagemaker_session.default_bucket()\n",
    "s3_output_path = \"s3://{}/{}/{}/{}/output\".format(s3_bucket, data_dir, s3_data_key, interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model image : 495149712605.dkr.ecr.eu-central-1.amazonaws.com/forecasting-deepar:1\n"
     ]
    }
   ],
   "source": [
    "#Obtain container image URI for SageMaker-DeepAR algorithm, based on region\n",
    "region = sagemaker_session.boto_region_name\n",
    "image_name = sagemaker.image_uris.retrieve(\"forecasting-deepar\", region)\n",
    "print(\"Model image : {}\".format(image_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload data to S3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training input preparation, all data togheter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *unique* train/test prefixes\n",
    "train_prefix   = '{}/{}'.format(data_dir_json, 'train')\n",
    "test_prefix    = '{}/{}'.format(data_dir_json, 'test')\n",
    "valid_prefix = '{}/{}'.format(data_dir_json, 'valid')\n",
    "benchmark_prefix = '{}/{}'.format(data_dir_json, 'benchmark')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_train = sagemaker_session.upload_data(path=data_dir_json_train, bucket=s3_bucket, key_prefix=train_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_test = sagemaker_session.upload_data(path=data_dir_json_test, bucket=s3_bucket, key_prefix=test_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_valid = sagemaker_session.upload_data(path=data_dir_json_valid, bucket=s3_bucket, key_prefix=valid_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_valid = sagemaker_session.upload_data(path=data_dir_json_benchmark, bucket=s3_bucket, key_prefix=benchmark_prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set DeepAR specific hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting target columns\n",
    "target_column = 'Adj Close'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DeepAR estimator parameters    \n",
    "hyperparameters = {\n",
    "    \"prediction_length\": str(prediction_length[1]), #number of time-steps model is trained to predict, always generates forecasts with this length\n",
    "    \"context_length\": str(context_length[1]), #number of time-points that the model gets to see before making the prediction, should be about same as the prediction_length\n",
    "    \"time_freq\": interval, #granularity of the time series in the dataset\n",
    "    \"epochs\": \"300\", #maximum number of passes over the training data\n",
    "    \"early_stopping_patience\": \"40\", #training stops when no progress is made within the specified number of epochs\n",
    "    \"num_layers\": \"4\", #number of hidden layers in the RNN, typically range from 1 to 4    \n",
    "    \"num_cells\": \"40\", #number of cells to use in each hidden layer of the RNN, typically range from 30 to 100\n",
    "    \"mini_batch_size\": \"128\", #size of mini-batches used during training, typically values range from 32 to 512\n",
    "    \"learning_rate\": \"1e-3\", #learning rate used in training. Typical values range from 1e-4 to 1e-1\n",
    "    \"dropout_rate\": \"0.12\", # dropout rate to use for regularization, typically less than 0.2. \n",
    "    \"likelihood\": \"student-T\" #noise model used for uncertainty estimates - gaussian/beta/negative-binomial/student-T/deterministic-L1\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimator Instantiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.estimator import Estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimator to be used with all data togheter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate a DeepAR estimator\n",
    "estimator = Estimator(image_uri=image_name,\n",
    "                      sagemaker_session=sagemaker_session,\n",
    "                      #image_name=image_name,\n",
    "                      role=role,\n",
    "                      instance_count=1,\n",
    "                      instance_type='ml.c4.xlarge',\n",
    "                      output_path=s3_output_path,\n",
    "                      hyperparameters=hyperparameters\n",
    "                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Job Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creation of a training job with stand alone time series (no dynamic features provided). Run only if no model has already been trained before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fit estimator on all data together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = date.today()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "# increment each time you don't run the training, to keep pointing to the right training artifact package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_daysago = today - datetime.timedelta(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_training_job_name = 'deepar-All-{}'.format(n_daysago)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SKIP if trainining the model is not needed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train and test channels\n",
    "data_channels = {\n",
    "    \"train\": input_data_train,\n",
    "    \"test\": input_data_test\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "estimator.fit(inputs=data_channels, job_name=all_data_training_job_name, logs='None')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Existing Model Instantiation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instatiation of a model from existing training artifacts (run only if a model has already been trained before)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model trained on all data together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stocks_model = sagemaker.model.Model(\n",
    "    model_data='{}/{}/output/model.tar.gz'.format(s3_output_path, all_data_training_job_name),\n",
    "    image_uri= image_name,\n",
    "    role=role)  # your role here; could be different name\n",
    "\n",
    "#trainedmodel.deploy(initial_instance_count=1, instance_type='ml.c4.xlarge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy and Create a Predictor\n",
    "\n",
    "Now that we have trained a model, we can use it to perform predictions by deploying it to a predictor endpoint.\n",
    "\n",
    "Remember to **delete the endpoint** at the end of this notebook. A cell at the very bottom of this notebook will be provided, but it is always good to keep, front-of-mind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing serializers\n",
    "from sagemaker.predictor import json_serializer, json_deserializer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deploying endpoint for global (all stocks together) estimator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_endpoint_name = 'DeepAR-ml-spp'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### run it once, then update the endpoint if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------!CPU times: user 428 ms, sys: 27.1 ms, total: 455 ms\n",
      "Wall time: 11min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "all_data_endpoint = all_stocks_model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type='ml.t2.medium',\n",
    "    endpoint_name=all_data_endpoint_name,\n",
    "    serializer=json_serializer,\n",
    "    deserializer=json_deserializer\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### update endpoint if needed:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All data model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "endpoint = all_data_endpoint.update_endpoint(\n",
    "    initial_instance_count=1,\n",
    "    instance_type='ml.t2.medium',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Predictions\n",
    "\n",
    "According to the [inference format](https://docs.aws.amazon.com/sagemaker/latest/dg/deepar-in-formats.html) for DeepAR, the `predictor` expects to see input data in a JSON format, with the following keys:\n",
    "* **instances**: A list of JSON-formatted time series that should be forecast by the model.\n",
    "* **configuration** (optional): A dictionary of configuration information for the type of response desired by the request.\n",
    "\n",
    "Within configuration the following keys can be configured:\n",
    "* **num_samples**: An integer specifying the number of samples that the model generates when making a probabilistic prediction.\n",
    "* **output_types**: A list specifying the type of response. We'll ask for **quantiles**, which look at the list of num_samples generated by the model, and generate [quantile estimates](https://en.wikipedia.org/wiki/Quantile) for each time point based on these values.\n",
    "* **quantiles**: A list that specified which quantiles estimates are generated and returned in the response.\n",
    "\n",
    "\n",
    "Below is an example of what a JSON query to a DeepAR model endpoint might look like.\n",
    "\n",
    "```\n",
    "{\n",
    " \"instances\": [\n",
    "  { \"start\": \"2009-11-01 00:00:00\", \"target\": [4.0, 10.0, 50.0, 100.0, 113.0] },\n",
    "  { \"start\": \"1999-01-30\", \"target\": [2.0, 1.0] }\n",
    " ],\n",
    " \"configuration\": {\n",
    "  \"num_samples\": 50,\n",
    "  \"output_types\": [\"quantiles\"],\n",
    "  \"quantiles\": [\"0.5\", \"0.9\"]\n",
    " }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate a Predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate a predictor to preprocess input data for predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from source_deepar.deepar_utils import DeepARPredictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All data based predictor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_predictor = DeepARPredictor(endpoint_name=all_data_endpoint_name, sagemaker_session=sagemaker_session)\n",
    "all_data_predictor.set_prediction_parameters(interval, prediction_length[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Predictions\n",
    "\n",
    "We can now use the model to get a predictions for input time series."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions on test dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ground truth:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gt = [df_ibm_test.iloc[-prediction_length[1]:]['Adj Close'], df_aapl_test.iloc[-prediction_length[1]:]['Adj Close'],\n",
    "           df_amzn_test.iloc[-prediction_length[1]:]['Adj Close'], df_googl_test.iloc[-prediction_length[1]:]['Adj Close']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all input and target (test) time series\n",
    "input_ts = [df_ibm_train, df_aapl_train, df_amzn_train, df_googl_train]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction output on all data together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predictions for all the time series\n",
    "test_predictions = all_data_predictor.predict(input_ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at one of them:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, index are just progressing of one day each row, wich is not stock price progression scheme in real life (e.g.: weekends are not trading days), so I'm going fix the index before going on with the analysis of results:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All data together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(test_predictions)):\n",
    "    test_predictions[i].index = test_gt[i].index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save data locally:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir_json_prediction = os.path.join(data_dir_json, 'prediction') # The folder we will use for storing data\n",
    "if not os.path.exists(data_dir_json_prediction): # Make sure that the folder exists\n",
    "    os.makedirs(data_dir_json_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All data together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since all of the predictions start and end on the same day, i just use one of them to get the datetime string\n",
    "start_date = test_predictions[0].index[0].date().strftime(format=\"%Y-%m-%d\")\n",
    "end_date = test_predictions[0].index[-1].date().strftime(format=\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction serialization:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All data together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(test_predictions)):\n",
    "    test_predictions[i].to_json(os.path.join(data_dir_json_prediction,\n",
    "                                             \"{}_{} - {}.json\".format(mnemonics[i], start_date, end_date)),\n",
    "                                orient='columns',date_format='iso')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction de-serialization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsz_test_predictions = []\n",
    "for i in range(0, len(test_predictions)):\n",
    "    dsz_test_predictions.append(\n",
    "        pd.read_json(os.path.join(data_dir_json_prediction,\n",
    "                                  \"{}_{} - {}.json\".format(mnemonics[i], start_date, end_date)),\n",
    "                     orient='columns', convert_axes=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, index normalization using target index, before using deserialized data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(test_predictions)):\n",
    "    dsz_test_predictions[i].index = test_gt[i].index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting the Future -  validation data predictions\n",
    "\n",
    "Now that we've tested our estimator on test set, we would like to see how it behaves on new data.\n",
    "So we'll feed it with validation data we set apart before starting the training phase.\n",
    "Create a formatted input to send to the deployed `endpoint` passing usual parameters for \"configuration\". The \"instances\" will, in this case, just be one instance, defined by the following:\n",
    "* **start**: The start time from wich we would like to make a prediction.\n",
    "* **target**: The target will be an empty list because this time period has no, complete associated time series.\n",
    "```\n",
    "{\"start\": start_time, \"target\": []} # empty target\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating an array comprising all of the validation dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid = [df_ibm_valid, df_aapl_valid, df_amzn_valid, df_googl_valid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = [df_ibm_test, df_aapl_test, df_amzn_test, df_googl_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieving ground truth data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_gt = [data['Adj Close'] for data in df_valid]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set start date as validation set start date, in order to complete the benchmark metrics task, I need to compare the performance of the model on the same dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All data together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# formatting start_date of each of the validation dataset (should be the same)\n",
    "start_date = [data.index[0] for data in df_valid]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieving predictions for all data together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get prediction response on validation data\n",
    "valid_predictions = all_data_predictor.predict_future(start_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_predictions = all_data_predictor.predict(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieving predictions for stand alone stocks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(start_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalizing index to real world trading dates:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All data together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(valid_predictions)):\n",
    "    valid_predictions[i].index = valid_gt[i].index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save data locally:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All data together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since all of the predictions start and end on the same day, i just use one of them to get the datetime string\n",
    "start_date = valid_predictions[0].index[0].date().strftime(format=\"%Y-%m-%d\")\n",
    "end_date = valid_predictions[0].index[-1].date().strftime(format=\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction serialization:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All data together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(valid_predictions)):\n",
    "    valid_predictions[i].to_json(os.path.join(data_dir_json_prediction,\n",
    "                                             \"{}_{} - {}_valid.json\".format(mnemonics[i], start_date, end_date)),\n",
    "                                orient='columns',date_format='iso')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction de-serialization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsz_valid_predictions = []\n",
    "for i in range(0, len(valid_predictions)):\n",
    "    dsz_valid_predictions.append(\n",
    "        pd.read_json(os.path.join(data_dir_json_prediction,\n",
    "                                  \"{}_{} - {}_valid.json\".format(mnemonics[i], start_date, end_date)),\n",
    "                     orient='columns', convert_axes=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, index normalization using target index, before using deserialized data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(valid_predictions)):\n",
    "    dsz_valid_predictions[i].index = valid_gt[i].index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results visualization\n",
    "\n",
    "The quantile data will give us all we need to see the results of our prediction.\n",
    "* Quantiles 0.1 and 0.9 represent higher and lower bounds for the predicted values.\n",
    "* Quantile 0.5 represents the median of all sample predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from source_deepar.display_quantiles import display_quantiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization of predictions on test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All together data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display predictions\n",
    "for i in range(len(test_predictions)):\n",
    "    display_quantiles(dsz_valid_predictions[i], valid_gt[i], ser_valid_ma[i], 'moving average')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from source_deepar.display_quantiles import display_quantiles_flask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization of predictions on test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All together data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display predictions\n",
    "quantiles_img = []\n",
    "for i in range(len(test_predictions)):\n",
    "    quantiles_img.append(display_quantiles_flask(dsz_valid_predictions[i], valid_gt[i], ser_valid_ma[i], 'moving average'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(quantiles_img[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stand alone predicted stocks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsz_valid_predictions[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display predictions\n",
    "for i in range(len(dsz_valid_predictions)):\n",
    "    display_quantiles(dsz_valid_predictions[i], valid_gt[i], ser_valid_ma[i], 'moving average')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics computation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have predictions on validation dataset, we can compute our metrics and compare it to benchmakr model performaces."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IBM Stock prices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean Absolute Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibm_dar_mae_loss = mean_absolute_error(test_gt[0], dsz_valid_predictions[0]['0.5'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ibm_dar_mae_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Root Mean Squared Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibm_dar_mse_loss = mean_squared_error(test_gt[0], dsz_valid_predictions[0]['0.5'], squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ibm_dar_mse_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean Absolute Percentage Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibm_dar_map_loss = mean_absolute_percentage_error(test_gt[0], dsz_valid_predictions[0]['0.5'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ibm_dar_map_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R<sup>2</sup> score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibm_dar_r2_score = r2_score(test_gt[0], dsz_valid_predictions[0]['0.5'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ibm_dar_r2_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AAPL Stock prices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean Absolute Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aapl_dar_mae_loss = mean_absolute_error(test_gt[1], dsz_valid_predictions[1]['0.5'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(aapl_dar_mae_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Root Mean Squared Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aapl_dar_mse_loss = mean_squared_error(test_gt[1], dsz_valid_predictions[1]['0.5'], squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(aapl_dar_mse_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean Absolute Percentage Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aapl_dar_map_loss = mean_absolute_percentage_error(test_gt[1], dsz_valid_predictions[1]['0.5'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(aapl_dar_map_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R<sup>2</sup> score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aapl_dar_r2_score = r2_score(test_gt[1], dsz_valid_predictions[1]['0.5'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(aapl_dar_r2_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AMZN Stock prices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean Absolute Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amzn_dar_mae_loss = mean_absolute_error(test_gt[2], dsz_valid_predictions[2]['0.5'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(amzn_dar_mae_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Root Mean Squared Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amzn_dar_mse_loss = mean_squared_error(test_gt[2], dsz_valid_predictions[2]['0.5'], squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(amzn_dar_mse_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean Absolute Percentage Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amzn_dar_map_loss = mean_absolute_percentage_error(test_gt[2], dsz_valid_predictions[2]['0.5'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(amzn_dar_map_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R<sup>2</sup> score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amzn_dar_r2_score = r2_score(test_gt[2], dsz_valid_predictions[2]['0.5'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(amzn_dar_r2_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GOOGL Stock prices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean Absolute Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "googl_dar_mae_loss = mean_absolute_error(test_gt[3], dsz_valid_predictions[3]['0.5'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(googl_dar_mae_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Root Mean Squared Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "googl_dar_mse_loss = mean_squared_error(test_gt[3], dsz_valid_predictions[3]['0.5'], squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(googl_dar_mse_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean Absolute Percentage Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "googl_dar_map_loss = mean_absolute_percentage_error(test_gt[3], dsz_valid_predictions[3]['0.5'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(googl_dar_map_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R<sup>2</sup> score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "googl_dar_r2_score = r2_score(test_gt[3], dsz_valid_predictions[3]['0.5'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(googl_dar_r2_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With reference to all the metrics, the DeepAR method has performed worse than the simple moving average in Adjusted Close stock prices predictions. Maybe better performances could be achieved by means of additional feature analyis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete the Endpoint\n",
    "\n",
    "Try your code out on different time series. You may want to tweak your DeepAR hyperparameters and see if you can improve the performance of this predictor.\n",
    "\n",
    "When you're done with evaluating the predictor (any predictor), make sure to delete the endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: delete the endpoint\n",
    "all_data_predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
